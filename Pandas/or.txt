# https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html
>>> import numpy as np
>>> import pandas as pd

# Creating a Series by passing a list of values, letting pandas create a default integer index:
>>> s = pd.Series([1, 3, 5, np.nan, 6, 8])
>>> s
0    1.0
1    3.0
2    5.0
3    NaN
4    6.0
5    8.0
dtype: float64

# Creating a DataFrame by passing a NumPy array, with a datetime index and labeled columns:
>>> dates = pd.date_range("20130101", periods=6)
>>> dates
DatetimeIndex(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04',
               '2013-01-05', '2013-01-06'],
              dtype='datetime64[ns]', freq='D')
>>> df = pd.DataFrame(np.random.randn(6, 4), index=dates, columns=list("ABCD"))
>>> df
                   A         B         C         D
2013-01-01  1.346263  0.021768  0.632130 -0.155758
2013-01-02  0.795611  0.942371  0.456549  1.196800
2013-01-03 -0.609220  0.559226 -1.389952 -0.558946
2013-01-04 -0.047837  2.987070  0.688361 -1.299909
2013-01-05 -2.067898 -2.398205 -0.747187  0.692277
2013-01-06  0.130598  0.199382  0.314944  0.070660

# Creating a DataFrame by passing a dict of objects that can be converted to series-like.

>>> df2 = pd.DataFrame(
...     {
...         "A": 1.0,
...         "B": pd.Timestamp("20130102"),
...         "C": pd.Series(1, index=list(range(4)), dtype="float32"),
...         "D": np.array([3] * 4, dtype="int32"),
...         "E": pd.Categorical(["test", "train", "test", "train"]),
...         "F": "foo",
...     }
... )
>>> df2
     A          B    C  D      E    F
0  1.0 2013-01-02  1.0  3   test  foo
1  1.0 2013-01-02  1.0  3  train  foo
2  1.0 2013-01-02  1.0  3   test  foo
3  1.0 2013-01-02  1.0  3  train  foo

# The columns of the resulting DataFrame have different dtypes.
>>> df2.dtypes
A           float64
B    datetime64[ns]
C           float32
D             int32
E          category
F            object
dtype: object

# If you’re using IPython, tab completion for column names (as well as public attributes) is automatically enabled. Here’s a subset of the attributes that will be completed:
>>>>>> # As you can see, the columns A, B, C, and D are automatically tab completed. E and F are there as well; the rest of the attributes have been truncated for brevity.
>>> # Here is how to view the top and bottom rows of the frame:
>>> df.head()
                   A         B         C         D
2013-01-01  1.346263  0.021768  0.632130 -0.155758
2013-01-02  0.795611  0.942371  0.456549  1.196800
2013-01-03 -0.609220  0.559226 -1.389952 -0.558946
2013-01-04 -0.047837  2.987070  0.688361 -1.299909
2013-01-05 -2.067898 -2.398205 -0.747187  0.692277
>>> df.tail(3)
                   A         B         C         D
2013-01-04 -0.047837  2.987070  0.688361 -1.299909
2013-01-05 -2.067898 -2.398205 -0.747187  0.692277
2013-01-06  0.130598  0.199382  0.314944  0.070660
>>> # Display the index, columns:
>>> df.index
DatetimeIndex(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04',
               '2013-01-05', '2013-01-06'],
              dtype='datetime64[ns]', freq='D')
>>> df.columns
Index(['A', 'B', 'C', 'D'], dtype='object')
>>> # DataFrame.to_numpy() gives a NumPy representation of the underlying data. Note that this can be an expensive operation when your DataFrame has columns with different data types, which comes down to a fundamental difference between pandas and NumPy: NumPy arrays have one dtype for the entire array, while pandas DataFrames have one dtype per column. When you call DataFrame.to_numpy(), pandas will find the NumPy dtype that can hold all of the dtypes in the DataFrame. This may end up being object, which requires casting every value to a Python object.
>>> # For df, our DataFrame of all floating-point values, DataFrame.to_numpy() is fast and doesn’t require copying data.
>>> df.to_numpy()
array([[ 1.34626329,  0.02176758,  0.63213016, -0.15575765],
       [ 0.79561131,  0.94237085,  0.45654877,  1.19680012],
       [-0.60921978,  0.55922554, -1.38995246, -0.55894618],
       [-0.04783748,  2.98707009,  0.68836121, -1.29990873],
       [-2.06789769, -2.39820482, -0.74718669,  0.69227693],
       [ 0.13059773,  0.19938236,  0.31494392,  0.07066023]])
>>> # For df2, the DataFrame with multiple dtypes, DataFrame.to_numpy() is relatively expensive.
>>> df2.to_numpy()
array([[1.0, Timestamp('2013-01-02 00:00:00'), 1.0, 3, 'test', 'foo'],
       [1.0, Timestamp('2013-01-02 00:00:00'), 1.0, 3, 'train', 'foo'],
       [1.0, Timestamp('2013-01-02 00:00:00'), 1.0, 3, 'test', 'foo'],
       [1.0, Timestamp('2013-01-02 00:00:00'), 1.0, 3, 'train', 'foo']],
      dtype=object)
>>> # DataFrame.to_numpy() does not include the index or column labels in the output.
>>> # describe() shows a quick statistic summary of your data:
>>> df.describe()
              A         B         C         D
count  6.000000  6.000000  6.000000  6.000000
mean  -0.075414  0.385269 -0.007526 -0.009146
std    1.189789  1.733459  0.856851  0.887977
min   -2.067898 -2.398205 -1.389952 -1.299909
25%   -0.468874  0.066171 -0.481654 -0.458149
50%    0.041380  0.379304  0.385746 -0.042549
75%    0.629358  0.846585  0.588235  0.536873
max    1.346263  2.987070  0.688361  1.196800
>>> # Transposing your data:
>>> df.T
   2013-01-01  2013-01-02  2013-01-03  2013-01-04  2013-01-05  2013-01-06
A    1.346263    0.795611   -0.609220   -0.047837   -2.067898    0.130598
B    0.021768    0.942371    0.559226    2.987070   -2.398205    0.199382
C    0.632130    0.456549   -1.389952    0.688361   -0.747187    0.314944
D   -0.155758    1.196800   -0.558946   -1.299909    0.692277    0.070660
>>> # Sorting by an axis:
